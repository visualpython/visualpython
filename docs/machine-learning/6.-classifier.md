# 6. Classifier



<figure><img src="../.gitbook/assets/image (153).png" alt="" width="211"><figcaption></figcaption></figure>

1. Click on the _**Classifier**_ under the _**Machine Learning**_ category.



<figure><img src="../.gitbook/assets/image (154).png" alt="" width="563"><figcaption></figcaption></figure>

2. _**Model Type**_: Select the Model Type of the classifier you want to use:
   * [Logistic Regression](6.-classifier.md#logistic-regression)
   * BernoulliNB
   * MultinomialNB
   * GaussianNB
   * [SVC(SupportVectorMachine Classifier)](6.-classifier.md#supportvectormachine-classifier)
   * [DecisionTree Classifier](6.-classifier.md#decisiontree-classifier)
   * [RandomForest Classifier](6.-classifier.md#randomforest-classifier)
   * [GradientBoosting Classifier](6.-classifier.md#gradientboosting-classifier)
   * [XGB Classifier](6.-classifier.md#xgb-classifier)
   * [LGBM Classifier](6.-classifier.md#lgbm-classifier)
   * [CatBoost Classifier](6.-classifier.md#catboost-classifier)
3. _**Allocate to**_: Specify the variable name to assign to the model.
4. _**Code View**_: Preview the generated code.
5. _**Run**_: Execute the code.



***

### Logistic Regression



<figure><img src="../.gitbook/assets/image (155).png" alt="" width="563"><figcaption></figcaption></figure>

1. _**Penalty**_: Specify the regularization method for the model. (l2 / l1 / elasticnet / none)
2. _**C**_: Adjust the regularization strength.
3. _**Random State**_: Set the seed value for the random number generator.



***

### SupportVectorMachine Classifier



<figure><img src="../.gitbook/assets/image (156).png" alt="" width="563"><figcaption></figcaption></figure>

1. _**C**_: C indicates the freedom of the model's regularization. A higher C value makes the model more complex to fit the training data.
2. _**Kernel**_: A function that maps data into higher dimensions. You can control the complexity of the model by selecting the kernel type.
   * _**Degree (Poly)**_: Degree determines the degree of the polynomial. A higher degree increases the complexity of the model.
   * _**Gamma (Poly, rbf, sigmoid)**_: Gamma adjusts the curvature of the decision boundary. A higher value makes the model fit the training data more closely.
   * _**Coef0 (Poly, sigmoid)**_: An additional parameter for the kernel, controlling the offset of the kernel. A higher value makes the model fit the training data more closely.
3. _**Random State**_: Set the seed value for the random number generator.



***

### DecisionTree Classifier



<figure><img src="../.gitbook/assets/image (157).png" alt="" width="563"><figcaption></figcaption></figure>

1. _**Criterion**_: Specify the metric used to select the node split. (squared\_error / friedman\_mse / absolute\_error / Poisson)
2. _**Max Depth**_: Specify the maximum depth of the trees.
3. _**Min Samples Split**_: Specify the minimum number of samples required to split a node to prevent excessive splitting.
4. _**Random State**_: Set the seed value for the random number generator.



***

### RandomForest Classifier



<figure><img src="../.gitbook/assets/image (158).png" alt="" width="563"><figcaption></figcaption></figure>

1. _**N estimators**_: Specify the number of trees to include in the ensemble.
2. _**Criterion**_: Specify the metric used to select the node split. Options include gini / entropy.
3. _**Max Depth**_: Specify the maximum depth of the trees.
4. _**Min Samples Split**_: Specify the minimum number of samples required to split a node to prevent excessive splitting.
5. _**N jobs**_: Specify the number of CPU cores or threads to use during model training for parallel processing.
6. _**Random State**_: Set the seed value for the random number generator.



***

### GradientBoosting Classifier



<figure><img src="../.gitbook/assets/image (159).png" alt="" width="563"><figcaption></figcaption></figure>

1. _**Loss**_: Specify the loss function to be used. Options include deviance / exponential.
2. _**Learning rate**_: Adjust the contribution of each tree and the degree to which the errors of previous trees are corrected. A large value may lead to non-convergence or overfitting, while a small value may increase training time.
3. _**N estimators**_: Specify the number of trees to include in the ensemble.
4. _**Criterion**_: Specify the metric used to select the node split. (friedman\_mse / squared\_error / mse / mae)
5. _**Random State**_: Set the seed value for the random number generator.



***

### XGB Classifier



<figure><img src="../.gitbook/assets/image (160).png" alt="" width="563"><figcaption></figcaption></figure>

1. _**N estimators**_: Specify the number of trees to include in the ensemble.
2. _**Max Depth**_: Specify the maximum depth of the trees.
3. _**Learning Rate**_: Adjust the contribution of each tree and the degree to which the errors of previous trees are corrected.
4. _**Gamma**_: Adjust the curvature of the decision boundary. A higher value makes the model fit the training data more closely.
5. _**Random State**_: Set the seed value for the random number generator.



***

### LGBM Classifier



<figure><img src="../.gitbook/assets/image (161).png" alt="" width="563"><figcaption></figcaption></figure>

1. _**Boosting type**_: Specify the boosting method used internally in the algorithm. (gbdt / dart / goss / rf (Random Forest))
2. _**Max Depth**_: Specify the maximum depth of the trees.
3. _**Learning rate**_: Adjust the contribution of each tree and the degree to which the errors of previous trees are corrected.
4. _**N estimators**_: Specify the number of trees to include in the ensemble.
5. _**Random State**_: Set the seed value for the random number generator.



***

### CatBoost Classifier



<figure><img src="../.gitbook/assets/image (162).png" alt="" width="563"><figcaption></figcaption></figure>

1. _**Learning rate**_: Adjust the contribution of each tree and the degree to which the errors of previous trees are corrected.
2. _**Loss function**_: Specify the loss function to be used. (RMSE / absolute\_error / huber / quantile)
3. _**Task type**_: Specify the hardware used for data processing. (CPU / GPU)
4. _**Max depth**_: Specify the maximum depth of the trees.
5. _**N estimators**_: Specify the number of trees to include in the ensemble.
6. _**Random state**_: Set the seed value for the random number generator.


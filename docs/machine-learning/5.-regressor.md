# 5. Regressor

<figure><img src="../.gitbook/assets/image (329).png" alt="" width="525"><figcaption></figcaption></figure>

1. Click on the _**Regressor**_ in the _**Machine Learning**_ category.

<figure><img src="../.gitbook/assets/image (330).png" alt="" width="563"><figcaption></figcaption></figure>

2. _**Model Type**_: Choose the regression model.

* [Linear Regression](5.-regressor.md#linear-regression)
* [Ridge / Lasso](5.-regressor.md#ridge-lasso)
* [ElasticNet](5.-regressor.md#elasticnet)
* [SVR(SupportVectorMachine Regressor)](5.-regressor.md#svr-supportvectormachine-regressor)
* [DecisionTree Regressor](5.-regressor.md#decisiontree-regressor)
* [RandomForest Regressor](5.-regressor.md#randomforest-regressor)
* [GradientBoosting Regressor](5.-regressor.md#gradientboosting-regressor)
* [XGB Regressor](5.-regressor.md#xgb-regressor)
* [LGBM Regressor](5.-regressor.md#lgbm-regressor)
* [CatBoost Regressor](5.-regressor.md#catboost-regressor)

3. _**Allocate to**_:  Enter the variable name to assign to the created machine learning model.
4. _**Code View**_: Preview the generated code.
5. _**Run**_: Execute the code.



***

### Linear Regression

<figure><img src="../.gitbook/assets/image (331).png" alt="" width="563"><figcaption></figcaption></figure>

1. _**Fit Intercept**_: Choose whether to include the intercept.



***

### Ridge / Lasso

<figure><img src="../.gitbook/assets/image (332).png" alt="" width="563"><figcaption></figcaption></figure>

1. _**Alpha**_: Adjust the level of regularization.



***

### ElasticNet

<figure><img src="../.gitbook/assets/image (333).png" alt=""><figcaption></figcaption></figure>

1. _**Alpha**_: Adjust the level of regularization.
2. _**L1 ratio**_: Adjusts the balance (ratio) between _**L1 (Lasso)**_ and _**L2 (Ridge)**_ regularization.



***

### SVR(SupportVectorMachine Regressor)

<figure><img src="../.gitbook/assets/image (334).png" alt="" width="563"><figcaption></figcaption></figure>

1. _**C**_: Represents the degree of freedom for model regularization. Higher values of C make the model more complex, fitting the training data more closely.
2. _**Kernel**_: Function mapping data to a higher-dimensional space, controlling model complexity.
3. _**Degree(Poly)**_: Determines the degree of polynomial.
4. _**Gamma(Poly, rbf, sigmoid)**_: Adjusts the curvature of the decision boundary.
5. _**Coef0(Poly, sigmoid)**_: Additional parameter for the kernel, controlling the offset. Higher values fit the training data more closely.
6. _**Random state**_: Sets the seed value for the random number generator used in model training.



***

### DecisionTree Regressor

<figure><img src="../.gitbook/assets/image (335).png" alt="" width="563"><figcaption></figcaption></figure>

1. _**Criterion**_: Specifies the measure used for node splitting.
2. _**Max depth**_: Specifies the maximum depth of the tree.
3. _**Min Samples Split**_: Specifies the minimum number of samples required to split a node.
4. _**Random state**_: Sets the seed value for the random number generator used in model training.



***

### RandomForest Regressor

<figure><img src="../.gitbook/assets/image (336).png" alt="" width="563"><figcaption></figcaption></figure>

1. _**N estimators**_: Specifies the number of trees in the ensemble.
2. _**Criterion**_: Specifies the measure used for node splitting.
3. _**Max depth**_: Specifies the maximum depth of the tree.
4. _**Min Samples Split**_: Specifies the minimum number of samples required to split a node.
5. _**N jobs**_: Specifies the number of CPU cores or threads to be used during model training.
6. _**Random State**_: Sets the seed value for the random number generator used in model training.



***

### GradientBoosting Regressor

<figure><img src="../.gitbook/assets/image (337).png" alt="" width="563"><figcaption></figcaption></figure>

1. _**Loss**_: Specifies the loss function used.
2. _**Learning rate**_: Specifies the learning rate.
3. _**N estimators**_: Specifies the number of trees in the ensemble.
4. _**Criterion**_: Specifies the measure used for node splitting.
5. _**Random State**_: Sets the seed value for the random number generator used in model training.



***

### XGB Regressor

<figure><img src="../.gitbook/assets/image (338).png" alt=""><figcaption></figcaption></figure>

1. _**N estimators**_: Specifies the number of trees in the ensemble.
2. _**Max depth**_: Specifies the maximum depth of the tree.
3. _**Learning rate**_: Specifies the learning rate.
4. _**Gamma**_: Specifies the minimum loss reduction required to make a further partition.
5. _**Random State**_: Sets the seed value for the random number generator used in model training.



***

### LGBM Regressor

<figure><img src="../.gitbook/assets/image (339).png" alt="" width="563"><figcaption></figcaption></figure>

1. _**Boosting type**_: Specifies the boosting type used in the algorithm.
2. _**Max depth**_: Specifies the maximum depth of the tree.
3. _**Learning Rate**_: Specifies the learning rate.
4. _**N estimators**_: Specifies the number of trees in the ensemble.
5. _**Random State**_: Sets the seed value for the random number generator used in model training.



***

### CatBoost Regressor

<figure><img src="../.gitbook/assets/image (340).png" alt="" width="563"><figcaption></figcaption></figure>

1. _**Learning rate**_: Specifies the learning rate.
2. _**Loss function**_: Specifies the loss function used.
3. _**Task Type**_: Specifies the hardware used for data processing.
4. _**Max Depth**_: Specifies the maximum depth of the tree.
5. _**N estimators**_: Specifies the number of trees in the ensemble.
6. _**Random State**_: Sets the seed value for the random number generator used in model training.

